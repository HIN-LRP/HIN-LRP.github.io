<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>HIN-LRP</title>

    <!-- Bootstrap Core CSS -->
    <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

    <!-- Theme CSS -->
    <link href="css/clean-blog.min.css" rel="stylesheet">

    <!-- Custom Fonts -->
    <link href="vendor/font-awesome/css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <link href='https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/css'>

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

    <script src="jquery.js"></script> 
    <script> 
    $(function(){
      $("#testhiggs").load("higgs.html"); 
    });
    </script> 
</head>

<body>

    <!-- Navigation -->
    <nav class="navbar navbar-default navbar-custom ">
        <div class="container-fluid">
            <!-- Brand and toggle get grouped for better mobile display -->
            <div class="navbar-header page-scroll">
                <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                    <span class="sr-only">Toggle navigation</span>
                    Menu <i class="fa fa-bars"></i>
                </button>
                <a class="navbar-brand" href="index.html">HIN-LRP</a>
            </div>

            <!-- Collect the nav links, forms, and other content for toggling -->
            <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
                <ul class="nav navbar-nav navbar-right">
                    <li>
                        <a href="index.html">Home</a>
                    </li>
                    <li>
                        <a href="lrp.html">More Math behind LRP</a>
                    </li>
<!-- 
                    <li>
                        <a href="contact.html">Contact</a>
                    </li> -->
                </ul>
            </div>
            <!-- /.navbar-collapse -->
        </div>
        <!-- /.container -->
    </nav> 

    <!-- Page Header -->
    <!-- Set your background image for this header on the line below. -->
    <!-- cite photo somehow: http://sf.co.ua/id143660 -->
    <header 
        class="intro-header" 
        style="background-image: linear-gradient(rgba(0, 0, 0, 0.5), rgba(0, 0, 0, 0.5)), url('img/lhc-photo.jpg'); ">
        <div class="container">
            <div class="row">
                <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                    <div class="post-heading">
                        <h1>HIN-LRP</h1>
                        <h2 class="subheading">GNN Interpretation in High Energy Physics</h2>
                        <span class="meta">by </a><b>Alex Luo & Yue Xiao</b></a> 
                            <!-- on August 24, 2014 -->
                        </span>
                    </div>
                </div>
            </div>
        </div>
    </header>

    <!-- Post Content -->
    <article>
        <div class="container-fluid">
            <div class="row">
                <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                    <h3 >ABSTRACT </h3>
                    
                        <p>While graph interaction networks achieve exceptional results in Higgs boson identification, GNN explainer methodology is still in its infancy. To introduce GNN interpretation to the particle physics domain, we apply layerwise relevance propagation (LRP) to our existing Higgs boson interaction network (HIN) to calculate relevance scores and reveal what features, nodes, and connections are most influential in prediction. We call this application HIN-LRP. The synergy between the LRP interpretation and the inherent structure of the HIN is such that HIN-LRP is able to illuminate which particles and particle features in a given jet are most significant in Higgs boson identification. The resulting interpretations are ultimately congruent with extant particle physics theory, with the model demonstrably learning the importance of concepts like the presence of muons, characteristics of secondary decay, and salient features such as impact parameter and momentum.</p>
                    <h2 class="section-heading">Intro</h2>

                    <p>Graph neural networks (GNN) are notoriously difficult to interpret, and those employed in the particle physics domain are no different. The graph interaction network has gained popularity with high energy physicists studying fundamental particles because this graph model achieves a highly competitive accuracy, while still working with relatively simple and unprocessed data. However, it is often not fully understood how or why the graph interaction networks make their classifications. Layerwise Relevance Propagation is a method we use to investigate how these models' inner workings might relate to the physical properties of the universe.</p>

                    <!-- <h3>the collider and the boson</h2> -->

                    <p>The Higgs boson is a particle that was hypothesized in 1964 by Peter Higgs, and essentially suggested to represent a universal field that is essentially responsible for mass. Big Deal, right? But it took decades before it was actually confirmed. Evidence finally appeared in 2012, at the large hadron collider, where scientists slam particles together really really fast to make other particles, rare and important particles like the higgs boson. But even with the particle collider constantly firing, a higgs event is hard to come by. Not only that, these detectors don’t get to pick up a literal higgs boson, because it exists for only a brief moment in time before decaying. The detector has to look at the decays, which come in the form of particle jets, which is, fittingly, the form of our data.</p>

                    <h2 class="section-heading">Particle Jet Data</h2>
                    <p>Context on these "jets", and our data. When a spray of particles hit the detector, the particle flight pathways and measurements are reconstructed into what are called tracks, and then grouped under cone-like clusters. But for the purposes of the model, it's good to know that we actually train on simulation data. Why? Because in quantum physics, we can only predict things probabilistically, so there is no way to confidently label real LHC data. We can say “oh, this was probably a Higgs boson,” but there’s no way of really fully knowing.</p>
                    
                    <p>The simulation constructs data on a fully ground up basis, building off of physics rules that have been theorized and confirmed. A benefit of this is that we can also lessen the rarity of the Higgs boson signal, so that it’s actually useful to train this model. In the simulated dataset, every entry is an individual jet, and each jet can have a variable number of particles, from as little as only 2 tracks to more than 60. For each jet we’ve isolated 48 features, features like momentum, mass, angle...ultimately, the goal is to look at a jet, and say whether it came from a Higgs signal, or is simply background.</p>


                    <p>There is a specific Higgs decay that we are looking for: the Higgs Boson decaying into a pair of b hadrons. There are several other permutations of higgs decay that can occur but H to bb is the most common. 
                        For the sake of simulation, we have this heavy artificial particle X, which decays into a pair of Higgs bosons, each of which decay into pairs of b hadrons. 
                        </p>
                    
                        <img src="img/Hbb.png" width=50% class='img-fluid center'/>
                    <p> To make things tougher, a given jet wouldn’t only have b hadrons, it’d also be full of other particles from adjacent and related decays. It’s altogether quite chaotic, which is why the classification problem in question is one suited for machine learning.
                    </p>

                    <h2 class="section-heading">The Higgs Boson Interaction Network Model</h2>

                    <p>That brings us to the Higgs Boson Interaction network, or HIN. This deep learning model finds pretty desirable success for the problem of Higgs boson identification. </p>

                    <p>Interactions networks are a kind of Graph Neural Net. As its name suggests, the interaction network excels at modeling the interaction of objects in complex systems. For the inputs, we take the simulated data and regroup it into a complete directed graph where every node is a particle, with the 48 feature values grouped by particle under the node, and every edge represents a directional relationship between particles.</p>
                    <img src="img/jet_graph.png" width=70% class='img-fluid center'/>
                    <p>Why do we represent the jets as graphs? Remember: a jet is a cluster of particles, and there is no inherit ordering of those particles. So graph models are desirable in that they reflect the absence of an inherit ordering. Even better, by fully connecting the graph, we are laying a truth for the model to understand. These particles are all connected in some way, they come from the same collisions, primary decays, maybe even the same secondary decays. It is then just up to model training to decide how connected they are and how important those connections are to determining whether it is a Higgs signal.
                    </p>

                    <p>
                        We built the model in PyTorch Geometric, which really helps facilitate a lot of the graph connections and the training structure. The core part of the HIN is the interaction block. 

                        The interconnectedness of this interaction block allows us to model the flow of information between nodes, or pairs of particles. PyTorch Geometric’s MetaLayer function abstracts a lot of this interconnectedness for us. Note how when the new edge hidden features are calculated, they influence the new node hidden features and global hidden features, and likewise when new node features are calculated, and so on.
                    </p>

                    <img src="img/model_architecture.png" width=90% class='img-fluid center'/>
                    <p>Each block is encoded with its respective transformation sequences: concatenations, linear transformations, batch normalizations, and ReLU activations. Our fully trained model will pass the input data through these blocks and return a softmaxed probability of how likely a jet is to be a Higgs boson signal.</p>
                    
                    <p>But most importantly here’s how it performs: a lovely 99% ROC AUC!
                        Compared to a straightforward boosted decision tree, our interaction network AUC boundary is nearly a right angle, which is quite ideal!                        
                   </p>
                   <img src="img/ROC.png" width=65% class='img-fluid center'/>
                    <p>
                       So we have this model, with a pretty splendid accuracy. But we don’t automatically understand how or why the model comes to these conclusions. This is where LRP comes in:
                    </p>

                    <h2 class="section-heading">Layerwise Relevance Propagation</h2>

                    <p>LRP is a technique that has found use in several other neural networks, especially image convolutional neural networks. More recently, its potential for GNN explanation is being discovered. Like water in a forking river, we branch across the model pathways, distributing relevance scores throughout each layer, all the way back to the inputs.
                        In simple words, we want to use LRP to find out how relevant each part of the input is to the output. So we take our input matrix, use some LRP magic, and for every value in the input, we get a corresponding score telling us how relevant it is the the output. 
                        </p>

                    <p>For our model, this means that LRP allows us to interpret model behavior on a jet by jet basis. Recall that the IN takes a jet as input, and outputs a Higgs boson likelihood for that jet. Here, we will reverse this process using LRP:  input the Higgs Boson likelihood, and in return we find out which particles, edges, even features of that jet input were most relevant.
                    </p>
                    <img src="img/input_to_relevance.png" width=90% class='img-fluid center'/>
                    <p>Now, you might have realized that LRP is very similar to a regular back-propagation of the model, except that it is propagating the relevance score. It operates on a gradient times input convention that refers to the Taylor expansion based calculation used to get relevancy at each layer.

                    </p>
                    <img src="img/lrp.png" width=90% class='img-fluid center'/>
                    <p>Look at this diagram. Follow the color density from the output as it moves backwards through the nodes. The more “relevant” nodes get more weight, and therefore color. For our model, this will allow us to highlight relevancy for both nodes, and edges.</p>
                    <img src="img/eq5.png" width=90% class='img-fluid center'/>
                    <p> Now for the equation we’re using to propagate relevance: The LRP-epsilon rule. The complicated math equation defined above is used at each layer to propagate relevance through the model. The rule is derived from the gradient times input concept, with the addition of one more element: The epsilon refers to a small quantity added to the denominator. With this, we avoid numerical instabilities, and also absorb some of the relevance score such that only the most important features are highlighted.</p>
                    
                    <h3>Dummy Model</h3>

                    <p>
                        We made fake data, and labeled it using an equation such that the only important features were 0 and 3. Everything else is useless noise.
                    </p>
                    <img src="img/sc.png" width=100% class='img-fluid'/>
                    <p>How do we read this map? The relevance scores are visualized in this heatmap, which has the same dimensions as the input. Each cell in the heatmap corresponds to an entry in the raw input, and it lights up if the entry is relevant to the final prediction. Positive or negative, the brighter the color, the more relevant it is to the prediction. The columns correspond to the 48 features whereas the rows correspond to the 10 tracks in the dummy jet. </p>
                    
                    <p>So clearly feature 3 is aggressively activated. You may be wondering why feature 0 is blank. We actually saw this result and circled back to our label equation, realizing that even though both feature 0 and 3 are in the equation, only feature 3 mattered to the label. And LRP realized that before we did.
                        So it’s kinda funny how this slight error in the construction of our sanity check actually exposed a deeper truth about the dummy data, which honestly just makes us more confident in the validity of the method.</p>

                        <blockquote>The dreams of yesterday are the hopes of today and the reality of tomorrow. Science has not yet mastered prophecy. We predict too much for the next year and yet far too little for the next ten.</blockquote>

                    <h2 class="section-heading">Visualizing Relevance with HIN-LRP</h2>
                    <p>We’ll be looking at four example jets and diving into how LRP interprets each. For each jet, we’ve created a pair of plots to visualize what our model sees for each jet, and what possibly led to the prediction made. </p>

                    <p>
                        The heatmap on the left looks familiar right? It’s mostly the same as the one we showed when with the dummy input example. Here, the heatmap is transposed to give an easier view of the 48 features. Each row corresponds to one feature, and each column now corresponds to a track in the jet, sorted by the top row track_pt, aka transverse momentum, in ascending order. Transverse momentum is known to be an important indicator of whether the jet is associated with Higgs boson.  The more intense the color in a cell the more relevant that entry of the input is to the Higgs probability output. Note that the signs of the relevance scores don’t correspond to positive or negative Higgs signal labeling. Only the magnitude matters. 
                    </p>
                </div>
            </div>
        </div>

        <div class="img-row">
            <div class="col-lg-1"></div>
                <div class="img-column">
                    <img src="img/plotguide.png" width=100% class='img-fluid center'/>
                </div>
            <div class="col-lg-1"></div>
        </div>

        <div class="container-fluid">
            <div class="row">
                <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                    <p>
                        To give a better idea of what our model sees in a jet, we can also visualize the significance of the nodes and edges in 3D space, as shown on the right. The 3D network plot projects polaresque coordinates phi and eta on the xy plane, and sets the z axis to momentum, allowing a clearer view of the dense graph representation of the jet and easy comparison to the heatmap. The sizes of the nodes are determined by node relevance scores, and the edge coloring is determined by their significance in the prediction. The edge significance is a positive, calculated value defined intuitively by the amount of information that flow through it. We can elaborate on the mathematical definition later if you’re interested. The edges receive a positive value between 0 to 1, and in the 3D network plot, the most important edges are highlighted in red.
                    </p>
                    <p>Let's look at some examples, where the heatmap is interactive so we can see feature values. A library of feature definitions can be found <a href="http://opendata.cern.ch/record/12102">here</a>.</p>
                    <h3>EXAMPLE 1: 99.94% Higgs Boson Signal</h3>
                    <p>In this example, the HIN is more than 99.9% confident in its prediction. The colored cells are mostly distributed in columns 14 and 21, suggesting that those two particles are most relevant to the prediction. </p>
                </div>
            </div>
        </div>

            <div class="img-row">
                <div class="col-lg-1"></div>
                <div class="img-column">
                    <object data="html/b3_j443_stretch.html" height=650 width=105% class="inner-image portrait"></object>
                </div>
                <div class="img-column">
                    <img src='img/b3j443_3d.png' width=100% class="inner-image center"></img>
                </div>
                <div class="col-lg-1"></div>
            </div>

            <div class="container-fluid">
                <div class="row">
                    <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                        <p>The Higgs boson decays into 2 b hadrons, right? Our heatmap implies that the model can perceive the two pronged nature of Higgs bosons decaying into the b hadron pair. Additionally, note how the highest momentum node is the most important, and in the 3D space we see the edge connecting to this node to be highly activated.  Physicists have shown that Higgs boson decay products are likely to have larger transverse momentum values.</p>
                        
                        <h3>EXAMPLE 2: 99.93% Higgs Boson Signal</h3>
                        <p>Here’s another example output of our HIN-LRP. Like in the previous example, the model is very confident that this jet is a Higgs boson signal. Compared to the heatmap in the previous example, this one displays an even more extreme relevance focus along just two columns, again alluding to the two pronged decay into b hadrons.</p>
                    </div>
                </div>
            </div>
            <div class="img-row">
                <div class="col-lg-1"></div>
                <div class="img-column">
                    <object data="html/b2_j334_stretch.html" height=650 width=105% class="inner-image portrait"></object>
                </div>
                <div class="img-column">
                    <img src='img/b2j334_3d.png' width=100% class="inner-image center"></img>
                </div>
                <div class="col-lg-1"></div>
            </div>

            <div class="container-fluid">
                <div class="row">
                    <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                        <p>Those two particles are the most significant nodes in the prediction, something that is clearly affirmed in corresponding 3D plot on the right. Notably, it is the lower momentum tracks in this jet that are more responsible for classification, but even in this situation momentum itself is still a highly relevant feature, as you can see in the blue cell in particle 1. This time the HIN also made its prediction with positional information in addition to the momentum data in feature `trackBTag_PtRel`, highlighted in blue. The bright red cells at `trackBTag_EtaRel` relates to the track’s location in space; `track_VTX_ass` and `track_fromPV` are related to its closeness to the primary vertex. </p>
                        
                        <h3>EXAMPLE 3: 99.88% Higgs Boson Signal</h3>
                        <p>This higgs boson jet is one of the first to get us excited about HIN-LRP’s ability to reveal the model’s relationship to physics. </p>
                    </div>
                </div>
            </div>
            <div class="img-row">
                <div class="col-lg-1"></div>
                <div class="img-column">
                    <object data="html/b3_j318_stretch.html" height=650 width=105% class="inner-image portrait"></object>
                </div>
                <div class="img-column">
                    <img src='img/b3j318_3d.png' width=100% class="inner-image center"></img>
                </div>
                <div class="col-lg-1"></div>
            </div>

            <div class="container-fluid">
                <div class="row">
                    <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                        <p>If we draw our attention to the feature track_isMu, aka “is this particle a muon”, we'd see that track 19 is indeed a muon. As that super blue square indicates, the muon track is extremely important information when it comes to the model’s classification. This is great because it reflects real physics phenomena: muons are actually relatively common outputs of b hadron decay. And if b hadrons are decaying, there’s a good chance those b hadrons were descended from a Higgs boson signal. It’s promising that our model has gleaned the importance of the muon, and shows that the HIN is able to learn physics rules from the chaotic collision events to simplify the prediction, and that LRP is able to illuminate the HIN’s understanding in this manner.
                        </p>
                        <h3>EXAMPLE 4: 99.95% Higgs Boson Signal</h3>
                    </div>
                </div>
            </div>
            <div class="img-row">
                <div class="col-lg-1"></div>
                <div class="img-column">
                    <object data="html/b9_j257_stretch.html" height=650 width=105% class="inner-image portrait"></object>
                </div>
                <div class="img-column">
                    <img src='img/b9j257_3d.png' width=100% class="inner-image center"></img>
                </div>
                <div class="col-lg-1"></div>
            </div>

        
            <br/>


            <p>Photographs by <a href="https://www.flickr.com/photos/nasacommons/">NASA on The Commons</a>.</p> 

            <!-- <div class="row" style="border:none; background:white; height:210px;">
                <div class="col-md-offset-1 col-md-5" style="padding-left: 40px;">  
                    <h3>Hello World</h3>
                    <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed hendrerit adipiscing blandit. Aliquam placerat, velit a fermentum fermentum, mi felis vehicula justo, a dapibus quam augue non massa.</p>
                </div>
                <div class="col-md-5">
                    <object data="html/b2_j334.html" height=1200 width=630></object>
                </div>

            </div> -->
            <!-- <div class="row" style="border:none; background:white; height:210px; justify-content: center; align-items: center;">
                <div class="col-xs-6">
                    <object data="html/b2_j334.html" height=1200 width=650  style="display: flex; justify-content: center; align-items: center;"></object>
                </div>
                <div class="col-xs-6" >  
                    <img src='img/b2j334_3d.png' width=650 class="img-fluid"></img>
                </div>
            </div> -->
        </div>
    </article>
<!-- 
    <div class="container-fluid" >
        <div>
            <img src='img/b2j334_3d.png' width=650 class="img-fluid"></img>
        </div>
        <div>
            <object data="html/b2_j334.html" height=1200 width=650></object>
        </div>
    </div> -->
    <hr>

    <!-- Footer -->
    <footer>
        <div class="container">
            <div class="row">
                <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                    <ul class="list-inline text-center">
                        <!-- <li>
                            <a href="#">
                                <span class="fa-stack fa-lg">
                                    <i class="fa fa-circle fa-stack-2x"></i>
                                    <i class="fa fa-twitter fa-stack-1x fa-inverse"></i>
                                </span>
                            </a>
                        </li> -->
                        <!-- <li>
                            <a href="#">
                                <span class="fa-stack fa-lg">
                                    <i class="fa fa-circle fa-stack-2x"></i>
                                    <i class="fa fa-facebook fa-stack-1x fa-inverse"></i>
                                </span>
                            </a>
                        </li> -->
                        <li>
                            <a href="https://github.com/HIN-LRP/Interpret-InteractionNetwork">
                                <span class="fa-stack fa-lg">
                                    <i class="fa fa-circle fa-stack-2x"></i>
                                    <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                                </span>
                            </a>
                        </li>
                    </ul>
                    <p class="copyright text-muted">Copyright &copy;DSC 180 Capstone group, Alex and Yue 2021</p>
                </div>
            </div>
        </div>
    </footer>

    <!-- jQuery -->
    <script src="vendor/jquery/jquery.min.js"></script>

    <!-- Bootstrap Core JavaScript -->
    <script src="vendor/bootstrap/js/bootstrap.min.js"></script>

    <!-- Contact Form JavaScript -->
    <script src="js/jqBootstrapValidation.js"></script>
    <script src="js/contact_me.js"></script>

    <!-- Theme JavaScript -->
    <script src="js/clean-blog.min.js"></script>

    
</body>

</html>
